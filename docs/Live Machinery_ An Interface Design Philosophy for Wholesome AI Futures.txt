L T
Live Machinery: An Interface
Design Philosophy for
Wholesome AI Futures
by Sahil 1st Nov 2024 AI Alignment Forum
Fluid interfaces for sensemaking at pace with AI development.
Register interest here for the workshop in November 2024 (or to be invited to
future workshops). To know some practical details, go to section 2.
Click here to help raise funds for the workshop and related events.
Apply for the AI Safety camp 2025 project on live machinery in tech and governance.
To learn more about the broader vision and engage with this strange community,
send me a DM.
Disclaimer: this is both an invitation and something of a reference doc. I've put the more
reference-y material in collapsible sections at the end. e bold font is for easier
skimming.
Cyborgism AI Frontpage
48
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 1/21

0. What is this?
   is is an extended rendezvous for creating culture and technology, for those enlivened
   by reimagining AI-based interfaces.
   Specically, we’re creating for the near future where our infrastructure is embedded
   with realistic levels of intelligence (i.e., only mildly creative but widely adopted) yet
   1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
   https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 2/21

full of novel, wild design paradigms anyway.
In particular, we’re going to concretely explore wholesome interface designs that
anticipate a teleattention era. Where cheap attentivity implies unstructured
meanings can scalably compose without requiring shared preformed protocols,
because moderate AI reliably does tailored, just-in-time “autostructuring".
e focus (which we will get to, with some patience) is on applying this to transforming
research methodology and interaction . is is what “live theory” is about: sensemaking
that can feed into a rich, sane, and heart-opening future.
Huh?
It’s a project for AI interfaces that don’t suck, to redo how (conceptual AI safety)
research is done.
Wait, so you think AI can only be mildly intelligent?
Nope.
But you only care about the short term, of “mild intelligence”?
Nope, the opposite. We expect AI to be very, very, very transformative. And therefore,
we expect intervening periods to be very, very transformative (as should you!).
Additionally, we expect even “very
2
transformative” intervening periods to be
crucial, and quite weird themselves, however short they might be.
In preparing for this upcoming intervening period, we want to work on the newly
enabled design ontologies of sensemaking that can keep pace with a world replete with
AIs and their prolic outputs. Using the near-term crazy future to meet the even crazier
far-o future is the only way to go.
So you don’t care about risks?
Nope, the opposite. is is all about research methodological opportunities meeting
risks of infrastructural insensitivity . As you’ll see in the last section, we will specically
move towards adaptive sensemaking meeting super adaptive dangers.
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 3/21

• • •
Watch a 10 minute video here for a little more background: Scaling What Doesn’t
Scale: Teleattention Tech.

1. What isLive Machinery /autostructuring?
   Autostructuring is about moving into fresh paradigms of post-formal design, where we
   scale productive interactions not via replicating xed structure but via
   ubiquitous attentive infrastructure. at’s a dense sentence, so let’s unpack.
   e only way to scale so far has been cookie-cutter replication of structure.
   For example, this text, even though quite adjustable, comes in a relatively xed
   formatting scheme. Bold, italics and underline have somehow become the universal
   three options on text. ey’re so ingrained that we rarely even imagine that we might
   need anything else. If you extend this yourself by creating a new style called “wave” or
   “overline”, you can’t copy it into a google doc and expect it to work. Who knows
   whether they’ll be wanted. Almost no fonts will be compatible, because they weren’t
   given any notice about “wave” or “overline”. People won’t know how or when to use it
   either.
   But maybe you would still like to use an “overline” style on your favorite fonts.
   Unfortunately, you don’t matter to the intermediating machines. It’s too expensive to
   take care of your whims. What happens when you share the doc with us? We’ll all have
   to add everyone’s crap to our shared schema, if you get your way. It just doesn’t scale.
   …unless we don’t have to share structure. Unless you can have a custom interface
   designed for you, attentive to your needs. AI might take minutes to do that now, cost a
   ton, and execute unreliably without feedback. But the cost, latency, and error is falling
   rapidly.
   Most importantly, a tailormade interface could fulll not just your individual
   structuring wishes around the doc, but also attend to interoperating wishes.
   1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
   https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 4/21

Intelligently displaying or substituting overline with underline for my view of your doc
could be something it comes up with. Instead of having a xed universal format, we
could have a plethora of self-maintaining, near-instantaneous translation between
the local structures that we each are happy with.
at’s a very simple example interface of what this new, anticipative design paradigm is
about. Anti-hype around the powers of AI in the next few years, but hype around the
powers of designing AI ubiquitously into our infrastructure. When we have attentive,
interoperating infrastructure that can, say, generate an entire UI from scratch in as much
time as it takes to open a website (which we’re certainly heading towards), we don’t need
duplication of xed/universal structure. Instead of distributing some nalized formal
specication (like code), we can distribute and match informal suggestions of
meaning (like comments or prompts) that immediately turn into formal outputs as
needed.
is expands scope and uidity, without losing interoperability. Instead of forcing
human subtlety to conform to xed shared structure just to be able to interoperate with
each other, AI can autostructure: auto-adapt to, co-create with, and harmonize with the
rich subtleties of specic living individuals and their communities.
Our eventual aim is to apply this interface-design-philosophy to postformal
sensemaking, especially for mitigating AI risk. We aim to see whether we can do
better than the rigid machinery of formal equations, which means redesigning the
machinery (i.e. interfaces, infrastructure, methodology) underlying formal theories
to take advantage of AI assistance. is is termed live theory .
is is an ambitious goal, so rst we will cut our teeth on (useful) interfaces in general,
not mainly theorization or sensemaking, so as to gain familiarity with the design
philosophy. e last section of this post is a primer on “live theory”.
Okay, I’m sold. Are we going to build some AI tools?
Not just tools; you build culture. You build the new design philosophies of interfaces
and interaction, when you can do things that don’t scale, at scale . is is not at all what
we're used to, and so it has barely shown up in the tools available today, despite the AI
hype (maybe even because of the hype).
Of primary interest here is this new ability to scale attentivity/sensitivity enabled by the
wish-fullling intelligences that will quickly become ubiquitous in our infrastructure.
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 5/21

e wide availability of even mild but fast and cheap intelligence supports scalable
detail-orientation and personal attention that can delegate, and even obviate, structuring
demands from humans (although we’re still free to).
Being able to autostructure things as easily as one might do, say, a lookup today,
undermines a lot of the fundamental design assumptions about how data, protocols,
interfaces, information, and abstraction operate. Each of these basic ideas were shaped
in a time when we’ve had to rely on xed formalisms and logistical structure to transport
our digital goods.
Without any hype, it is possible to say that we’re entering a “postformal” era where you
don’t have to formalize to make things workable. Comments are often as good as code
(increasingly so, as tech improves), maybe even better and more exible. is holds the
possibility of moving our interfaces away from abstracted commands and controls and
into subtle wishes and prayers.
“Wishes and prayers”?! Until that last bit I was hopeful you
were doing the opposite of “build an AGI god” thing that
everyone seems to end up at!
Yes, this is very much not about building an AGI god.
Here’s a denition of “prayer” apt for infrastructure that is mildly adaptive but widely
adopted.
"Prayer", not as in "pray to an AI god”, but "prayer" as in "send out a message to a fabric of
intelligence without trying super hard to control or delineate its workings in detail, in a
way that is honest to you rather than a message controlled/built for someone or something
else.
When machines can actuate potential ideas from 1 to 100 nearly instantaneously, most
of the work of living beings will be to supply heartfelt relevance, meaning, vision; the 0 to

1. (Note that being able to generate “ideas” is not the same as being clued in to
   relevance; mildly intelligent AI can be of great help with ideas, but can lack subtle
   connection to meaningfulness and be boring or hallucinatory or deceptive.)
   However, we living beings will assist the wish-fullling machine apparatus that will
   surround us, especially while we’re still in the mild-to-moderate intelligence levels. is
   will not look like detailed modular commands or recipes (nor genies that require no
   [1]
   1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
   https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 6/21

interaction at all) but context-sensitive hints and anchors that will feed into the AI-
assisted actuation.
So AI is going to do the meaning-making for me?
No. is is neither about you, nor the AI.
Meaning happens in the middle, between us. Existing machinery both supports
(because of scale and speed) and hinders (because of homogenization and xity) the
dynamics of rich meaning.
Trying to zero in on the relationship between you and AI bots is missing the point.
ere are no endless spammy AI bots in this vision. Just because it is cheap to
generate AI content, doesn’t mean you should spam the user and abdicate responsibility
for tasteful design.
is is about how you and I will relate to each other via AI as mostly-ignorable
infrastructure. Like the internet, which is rarely the topic of conversation even in your
internet-mediated video calls, and only foregrounded when the internet doesn't work
right for a few seconds.
So this is about matching your postformal prayers with mine, and uidly creating just-
in-time interfaces and structures that precisely suit our wishes. is means interfaces
do not have to work with tradeos that come with preformed/universal structures. ey
are free to be specic to the heterogeneous context, thanks to attentive infrastructure.
What’s an example of a wish-based, postformal interface?
Check out the table below for a mix of ideas. Skip directly to the table if you’re tired of
abstract prefacing.
Preface for the table.
If you do have more patience, some more on the table and the two most important
columns:
Table Format
e zeroth column is the problem area. Each row is a particular problem
area, usually involving some kind of logistics of distribution of meaning,
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 7/21

followed by particular design frames for solutions.
e rst column is the formal approach, which involves informational
packaging before exporting. is is the default of using thoughtful but xed
structure to make it possible to move information and meaning around, and
until recently, the only way to scale information products.
e second column is the “tacked on” AI or the lazy approach. is is the
way most incorporate AI today, and serves as a useful contrast. It's usually
chatbots, translations, or summaries.
e third column is the postformal or live way of designing things with
AI, which is the style we’ll explore. e fourth column then provides
additional commentary for this third column.
Lazy vs Live
Sometimes lazy design does not seem too far from the postformal ones. is
is expected, of course, as these possibilities become clearer to everyone. e
dierence between live and lazy is in whether it anticipates designing for
AI technology, in whatever form, to become extremely cheap, fast,
integrated. If it shies away from that, it might not be taking the future
seriously enough.
A column omitted for the sake of space is the “AGI” column, which is also
lazy. It is the other extreme of unimaginativeness. Expecting a silver bullet for
literally everything that excludes anything else is a design blackhole. So both
ends of “just add AI to what we’ve always done” and “just let AGI do anything
there is to be done” are vague and unspecic. e rich middle between
these two extremes is where reality and thoughtfulness lies. You’ll get a taste
of these in the table.
“Reality” doesn’t mean everything has to be buildable right away. In fact,
when tech picks up speed (as is underway), anticipations and potentials
become more and more real, both in terms of relevance and shaping of the
future.
Building to anticipated adaptivity (i.e., nishing ability, to fulll wishes with
executional excellence) in our machinery + adoption (i.e. wishing ability, a
collective culture of wholesome wishing) can foster beautiful dances.
A quick overview of what to look for in the examples. An extended
explanation of these adjectives is at the bottom of the post .
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 8/21

[Contrasting descriptors of live and lazy]
AI “tacked on” (or lazy) AI postformal (or live)
unscoped
supplements formalism
un- or over- collaborative
bottlenecked by modularity
centralized meaning
mass production
single-use tool
single-distribution
decontextualizing
specic
supplants formalisms
collaborative
seamless and exploits contextuality
peer-to-peer meaning
tailormade production
ongoing interfacing layer
pluralistic-distribution
recontextualizing
Table of Contrasting Examples
e ones in orange are not representative, only warm-ups chosen for their familiarity
and simplicity. e ones in green are the main ones.
A specic
problem
Formal (non
AI)
Structuring
AI “tacked
on” (or lazy)
AI postformal
(or live)
Pay attention to
this column.
Additional
Commentary
Device
authentication.
Enter a keycode
or password.
[thankfully,
we probably
skipped this
as a
civilization]
Face/ngerprint
detection.
ese three are
non-
representative
but simple
examples that
Talking to
people across
the world.
Everybody
learns a
common
AI translation
tools are
integrated into
video calls so
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 9/21

already exist,
to warm-up on
columns.
language, like
English.
everyone can
speak and hear
in their own
language.
Text input into
a device.
Discrete
keypresses on a
keyboard.
Speech-to-
text.
Swipe on
keyboard.
Disseminating
information to
the public.
Books and
posts written as
formal
publications.
Reader
uploads a
book to an AI
chatbot, and
tends to ask
for
summaries or
clarications.
e writer
writes not a
book, but a
book-prompt
that carries
intuitions for
the insights. An
economics
textbook-
prompt, for
example, could
contain
pointers to the
results and
ideas but the
language,
examples, style
would combine
with readers’
backgrounds
(and prayers) to
turn into
independent
textbooks for
each reader.
Importantly,
this frees up
producers of
books from
is is a bit lik
text reow, but
content. Endle
atomizing
dialogue is
avoided, so you
still get a book
experience.
“Prayers” that
readers could h
are things that
could be appen
to the original
book-prompt
(which is the
“prayer” from
writer). Such a
(“I’m looking f
something tha
would make m
laugh”).
ey don't hav
be independen
books either, a
can be
interdependen
Commentary o
your own book
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 10/21

having to
straddle and
homogenize the
range of
audiences they
might want to
speak to
can be translat
to someone els
book.
Organizing
information
for yourself.
Put text and
media in les,
put les in
folders, index
them and make
them
searchable.
Tags, colors,
pins, reminders
in your Notion/
Obsidian/Roam
notebook.
Talk-to-your-
data & RAGs
(retrieval-
augmented
generation)
let you
retrieve your
information
in natural
language and
interact with
it.
Smartly
suggested
tags for your
notebook.
Having to
“place”
information in
“containers” is
unnecessary
rigidity of
structure.
Instead, you
dump
information
and insights as
needed in one
“place”, with
relationships
and indexing
hints/prayers
produced in
collaboration
with AI that
leaves ow
uninterrupted.
ese hint-
annotations can
be used to make
the store and
retrieve actions
more uidly
entangled.
Views and
attention-cycles
Frequencies of
stability of
structure and
cycling conten
will be an
enduring artfo
that can easily
turn predatory
not left to be a
artform.
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 11/21

over this
information are
created for you
just-in-time,
replacing
permanent
structure.
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 12/21

Privacy in
publishing the
outputs of
conversation.
Manually
create formal
output and
omit private
stu; or publish
recording but
use formal
tools of
pausing/editing
Have an AI-
generated
summary of
conversation
and prompt it
to delete
private
seeming
details. en
distribute this
common
output via
your blog or
paper.
In the midst of
conversation,
talk uidly but
occasionally
place a “wish”
of “privacy
here” to
listening AI,
whenever it
seems relevant.
On demand
from a specic
‘consumer of
the
conversation’,
the AI
combines these
hints and
background
details to
produce just-in-
time outputs,
that regenerate
the private
information so
as to omit
details but
preserve
meaning and
rhythm.
e uid natur
post-formal
interfaces mea
you can stream
everything all t
time.
Privacy can be
applied
automatically,
personal AI tra
on your person
privacy-needs,
fewer annotati
are needed ove
time. GenAI ca
handle privatiz
of even faces, s
and replace the
with randomly
generated ones
Mathematics
and
theorization
generally, for
distributing
insight.
Create formal
denitions and
systems that
capture
invariants.
AI proof
assistants
that help with
the process
from taking
mathematical
Instead of
crafting
formalisms,
humans craft
formalism-
prompts that
e next sectio
on Live eor
covers this.
new kinds of
reliability (pro
and interopera
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 13/21

formalisms
(that still
capture
context-
independent
invariants) to
computerized
proof-
formalisms
that everyone
can use.
serve as
anchoring
insight more
than any
formalism can.
ese prompts
become
relevant
formalisms and
denitions
near-
instantaneously
for any local
application,
created in a
context-
sensitive way
with the help of
AI. ey don't
have to be
formally
compatible, and
so can scaold
specics that
aren’t
capturable by
invariants.
ey can
interoperate
translation of
private notation
and generated
distillations.
(corresponden
themselves wo
be postformal,
are still under
conceptual
investigation. E
to-end functio
yet reliable
sensemaking in
the far enough
future might
replace
systematizatio
entirely.
Regulation Codication of
law; regulations
are static,
A chat-bot
interface for
the
regulations
Regulations
used to
articulate
specic
Live
Governance is
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 14/21

Cool! Do I get to slap a chatbot on something to make a Talk-
To-Your-X interface?
No, you will be disqualied and blackmailed. Chatbots are considered a thoughtcrime in
this workshop.
In seriousness, we’re looking for interfaces that aren’t endlessly nauseatingly demanding
of the user under the pretext of “choice”. We want to provide the user with some uid,
liberating constraints. Surely we can look further than just “do what you’ve always been
doing, but also query a chatbot”.
Here are some questions that highlight our design focus (scroll down for more),
although not comprehensive for obvious reasons:
uniform and
universal.
E.g. a building
code
for home-
builders to
talk to.
E.g. a
building code
chatbot
objectives;
these can be
specialized to
local context.
E.g. 90% of new
houses should
be able to
withstand 1-in-
100 year natural
disasters.
You
communicate
your building
plans to the AI,
which can then
advise if they
are adequate to
the area. If not,
it can
recommend
improvements.
whole stream h
with more deta
and backgroun
the link. For A
policy especial
might make it
easier to do
substrate-sens
risk
management o
catastrophe.
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 15/21

1. Is it live, rather than lazy?
2. Is the problem space specic?
3. Does it innovate on locating an implicit xed structure that we didn't even realize
   is optional if AI is involved? Or did it do barely better than a chat/summarization
   interface?
4. How much is it prepared to take advantage of i) increased adaptivity and ii)
   increased adoption in the future?
5. Does it embrace new cultures of interaction, rather than just new tech? Does it
   manage to not be endless generative spam?
6. If there is dystopic potential of the tech, does it seem to notice and mitigate or
   transmute that?
   Some more specic design principles with examples in the appendix.
7. Who am I (the participant) and what am I
   going to do in the workshop?
   As mentioned above, participants are invited to imagine and build
   not just tools; you build culture. You build the new design philosophies of
   interfaces, when you can do things that don’t scale, at scale .
   You are a good t if any of these apply to you:
   Vibed with this post for some reason / felt like you were waiting for this, and
   willing to stick around for 6 days to nd out why
   Excited and/or concerned about the future, tired of doomerism and e/acc, bored of
   both incremental stories and overhype for AI, and want some vivid details and
   texture for the actual transformations in the future dammit
   Have looked at some approaches to AI alignment, bemoan the overindexing on
   current paradigm, charmed by mathematical, conceptual, foundational advances
   1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
   https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 16/21

but skeptical of relevance to impact
Are annoyed by bureaucratic, homogenizing, or centralizing patterns in all the
things that matter to you, and open to seeing the deeper manifestations of these in
operation... or are generally energized by pioneering honesty
Are at the intersection of/ever-ready to skillfully marry: metaphysics &
engineering, computer science & sociobiological lenses, rigor & ritual, the explicit
& the implicit
Are a nerd about meta-systematicity or adult development or collective
sensemaking
Are bored of abstract conversations about wisdom and sensemaking and
relationality and uidity
Can easily recall fundamental shifts in your view of the world and have an appetite
for/midwing interest in inchoate emergence
Say things like “I’m not really a rationalist” or “I’m not really an EA” or similar yet
instinctively apply acausal decision theory to your donations
See everything as code/computation, breathe Curry-Howard, and are now curious
about trying to see everything as comments too
Hate technology, have a meditation practice, excited about the truth of your body,
tired of people conating pain with suering and thinking with awareness, or
generally spy the signicance of aesthetics and salience and relationality especially
in mindlike phenomena
Fond of conceptual research, have any experience in any kind of design or
engineering
Triggered yet compelled, or need to rant about how this whole agenda is
simultaneously undesirable, impossible, incomprehensible
Don’t understand or think you can contribute to any of this, but you’d love to listen
to or be in the presence of such work
Aspire to cultivate the deepest respect for beings
e only real requirements are open-mindedness and integrity. It might look STEM-
centered, but it’s no prerequisite. Some experience with, or even just valuing of
systematicity is greatly helpful though.
What is the schedule of my participation?
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 17/21

is is a 6-day workshop, from November 21st to 26th, happening at the EA Hotel in
Blackpool.
A detailed schedule will be provided to the selected participants. We will engage in at
least the following, with some more info in the rest of this post:
Design & build tech: Designing interfaces that embody the live philosophy, guided
by the design recipes, the design principles, the design pillars , and the submission
template. is includes ideation and prototyping.
Co-create culture: where we begin practicing and experimenting with the shared
use of teleattention technology before it exists by recording informal wishes
(mundane ones, like “make this section of the recording private”) to be fed into
near future AI for enactment. Information cryonics!
Opportunity Modeling, where we acknowledge the responsibility of anticipative
design, in order for plans to be resilient to rapidly changing reality. ere are some
simple, specic frameworks for this, with some info below.
Live eory will be the major focus, which will be discussing and experimenting
with proofs-of-concept for redoing theoretical machinery. Again, see below for a
brief and largely insucient primer, or keep an eye on the sequence that this is a
part of .
Relatedly, expect to be paired with some grizzled conceptual alignment
researchers, by sitting in on meetings and seeing if there is any “ResearchOps”
assistance that can be provided that can remain relatively seamless.
You can also expect
Relational subtlety and presence-centered group processes
Conversations that respect the distinction between meaningful and formal
A fair amount of slack
A report on previous hackathons in this paradigm is being processed and will be linked
here soon.
How do I sign up?
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 18/21

Register interest here for the workshop in November 2024 (or to be invited to future
workshops).
• • •
e main invitation ends here, and what follows is reference material for the above.
I'd recommend reading it if you'd enjoy more texture. e appendix, especially
• • •
Opportunity Modeling
Live eory
Design Principles

Also: subtlety, taste, renement. ese do not t the usual connotations of "0 to 1" but they are
still microcosms of the same movement.
^
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 19/21

Mentioned in
101
64
27
Previous:
Live eory Part 0: Taking Intelligence
Seriously
3 comments 101 karma
3 comments, sorted by top scoring
Moderation Log
lucid_levi_ackerman 3 0
[ ]
---

Nice to hear people are making room for uncomfortable honesty and weirdness. Wish I could have
attended.
DusanDNesic 2 0
[ ]
---

I'm very sad I cannot attend at that time, but I am hyped about this and believe it to be valuable, so I am
writing this endorsement as a signal to others. I've also recommended this to some of my friends, but
alas UK visa is hard to get on such short notice. When you run it in Serbia, we'll have more folks from
the eastern bloc represented ;)
Sahil 1 0
[ ]
---

Thank you, Dusan!
Next time there will be more notice, and also a more rened workshop!
Live eory Part 0: Taking Intelligence Seriously
AI Craftsmanship
e Logistics of Distribution of Meaning: Against Epistemic Bureaucratization
1mo
2mo
2mo
1
1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 20/21

1/10/25, 6:10 PM Live Machinery: An Interface Design Philosophy for Wholesome AI Futures — LessWrong
https://www.lesswrong.com/s/aMz2JMvgXrLBkq4h3/p/9KamjXbTaQpPnNsxp 21/21
